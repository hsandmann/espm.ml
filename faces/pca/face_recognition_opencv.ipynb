{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "04. Machine Learning : Face Recognition",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4HvLS4peL0V"
   },
   "source": [
    "## OpenCV: PCA\n",
    "\n",
    "fonte: [https://docs.opencv.org/3.4/da/d60/tutorial_face_main.html](https://docs.opencv.org/3.4/da/d60/tutorial_face_main.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "he_NK4AsD64B"
   },
   "source": [
    "### Preparando ambiente"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ii5EBkDZDz4I"
   },
   "source": [
    "!pip install --upgrade face_recognition\n",
    "!pip install --upgrade opencv-python"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\n",
      "Requirement already up-to-date: face_recognition in /usr/local/lib/python3.7/site-packages (1.3.0)\r\n",
      "Requirement already satisfied, skipping upgrade: Click>=6.0 in /usr/local/lib/python3.7/site-packages (from face_recognition) (7.0)\r\n",
      "Requirement already satisfied, skipping upgrade: dlib>=19.7 in /usr/local/lib/python3.7/site-packages (from face_recognition) (19.17.0)\r\n",
      "Requirement already satisfied, skipping upgrade: face-recognition-models>=0.3.0 in /usr/local/lib/python3.7/site-packages (from face_recognition) (0.3.0)\r\n",
      "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.7/site-packages (from face_recognition) (6.1.0)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/site-packages (from face_recognition) (1.17.2)\r\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\n",
      "Requirement already up-to-date: opencv-python in /usr/local/lib/python3.7/site-packages (4.5.1.48)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14.5 in /usr/local/lib/python3.7/site-packages (from opencv-python) (1.17.2)\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4F9X4KAENB4"
   },
   "source": [
    "### Importando bibliotecas e definindo funções"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kV0LT71MEL3b"
   },
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, Javascript, Image, clear_output\n",
    "from google.colab.output import eval_js\n",
    "from google.colab.patches import cv2_imshow\n",
    "import urllib.request\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  resp = urllib.request.urlopen(data)\n",
    "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "\n",
    "  return image"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-991e4acd6da3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mIPython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdisplay\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdisplay\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mJavascript\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mImage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclear_output\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mgoogle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolab\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutput\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0meval_js\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mgoogle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolab\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpatches\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcv2_imshow\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0murllib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kk4GPqnuECqk"
   },
   "source": [
    "### Importando faces conhecidas\n",
    "download das fotos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AgbGv_-MEIwu"
   },
   "source": [
    "!wget -O humberto.jpg 'https://media-exp1.licdn.com/dms/image/C4D03AQFkFrCH3eVxQw/profile-displayphoto-shrink_100_100/0/1616287577028?e=1623283200&v=beta&t=49wqUyWCR36zzmkdBAbRs4ey_VRJzTH0XgbhdKxbflw'\n",
    "!ls -la"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gl8YNXtDEzEO"
   },
   "source": [
    "### Carregando imagens para serem reconhecidas"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RAND8H9cE8cP"
   },
   "source": [
    "# Load a sample picture and learn how to recognize it.\n",
    "humberto_image = face_recognition.load_image_file(\"humberto.jpg\")\n",
    "humberto_face_encoding = face_recognition.face_encodings(humberto_image)[0]\n",
    "\n",
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    humberto_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Humberto\"\n",
    "]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bI546zgnE9wa"
   },
   "source": [
    "### Reconhecendo faces"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1--M4ohHpc07"
   },
   "source": [
    "# Inicializa as variáveis de resultados\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "first = True\n",
    "\n",
    "filename = 'result.jpg'\n",
    "scale = 4\n",
    "\n",
    "while True:\n",
    "    # Captura um simples frame (bate uma foto)\n",
    "    frame = take_photo()\n",
    "\n",
    "    # Reduz a dimensão do frame para 1/4 para acelerar o processo de reconhecimento\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=1/scale, fy=1/scale)\n",
    "\n",
    "    # Converte o frame de BGR (OpenCV usa) para RGB (face_recognition usa)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Procura todas as faces no frame atual\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # Procura a face na lista de faces conhecidas\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # Dentre as escolhidas, encontrar a face com a menor distância\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            face_names.append(name)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "    # Exibe os resultados\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Rescala a image para o tamanho original\n",
    "        top *= scale\n",
    "        right *= scale\n",
    "        bottom *= scale\n",
    "        left *= scale\n",
    "\n",
    "        # Desenha um retângulo em torno da face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Desenha um rótulo para a face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (255, 0, 0), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "        \n",
    "    clear_output()\n",
    "    # Exibindo o resultado\n",
    "    cv2_imshow(frame)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7aid0LsAfOIR"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}